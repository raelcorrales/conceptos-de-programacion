# **üìå Gu√≠a de Dataflow (Apache Beam) para Data Engineers**  

## **1Ô∏è‚É£ Introducci√≥n a Dataflow y Apache Beam**  
### **üîπ ¬øQu√© es Dataflow?**  
Google Cloud Dataflow es un servicio **serverless** para ejecutar pipelines de procesamiento de datos en tiempo real o en lotes, basado en **Apache Beam**.  

‚úî **Serverless**: No requiere gesti√≥n de infraestructura.  
‚úî **Escalabilidad autom√°tica**: Se adapta a la carga de trabajo.  
‚úî **Integraci√≥n con GCP**: Funciona con BigQuery, Pub/Sub, Cloud Storage, etc.  
‚úî **Modelo unificado**: Permite el mismo c√≥digo para batch y streaming.  

### **üîπ ¬øQu√© es Apache Beam?**  
Apache Beam es un **framework de procesamiento de datos** que permite escribir pipelines de manera agn√≥stica a la plataforma de ejecuci√≥n (Dataflow, Spark, Flink, etc.).  

**Arquitectura de Apache Beam:**  
1. **Pipeline** ‚Üí Representa el flujo de datos.  
2. **PCollection** ‚Üí Estructura de datos distribuida e inmutable.  
3. **Transformations** ‚Üí Operaciones aplicadas a los datos (`ParDo`, `GroupByKey`, `Windowing`).  
4. **Runner** ‚Üí Motor de ejecuci√≥n (Dataflow, Spark, Flink, DirectRunner).  

---

## **2Ô∏è‚É£ Procesamiento Batch vs Streaming en Dataflow**  
### **üîπ Procesamiento Batch**  
‚úî Procesa datos **est√°ticos** y preexistentes.  
‚úî Se ejecuta en intervalos definidos (diario, semanal, etc.).  
‚úî Ejemplo: **C√°lculo de ventas diarias desde BigQuery**.  

**Ejemplo de Pipeline Batch en Apache Beam (Python)**  
```python
import apache_beam as beam

with beam.Pipeline() as p:
    (p
     | 'Leer Datos' >> beam.io.ReadFromText('gs://mi-bucket/datos.csv')
     | 'Transformar' >> beam.Map(lambda x: x.upper())
     | 'Guardar' >> beam.io.WriteToText('gs://mi-bucket/salida'))
```

### **üîπ Procesamiento Streaming**  
‚úî Procesa datos en **tiempo real**.  
‚úî Usa ventanas de tiempo (`Fixed`, `Sliding`, `Session`).  
‚úî Ejemplo: **Procesamiento de eventos de usuarios en Pub/Sub**.  

**Ejemplo de Pipeline Streaming en Apache Beam (Python)**  
```python
with beam.Pipeline() as p:
    (p
     | 'Leer desde Pub/Sub' >> beam.io.ReadFromPubSub(topic='projects/mi-proyecto/topics/mi-topico')
     | 'Transformar' >> beam.Map(lambda x: x.upper())
     | 'Escribir en BigQuery' >> beam.io.WriteToBigQuery('mi-proyecto:mi_dataset.mi_tabla'))
```

### **üîπ Comparaci√≥n entre Batch y Streaming**  
| **Aspecto** | **Batch** | **Streaming** |
|------------|---------|------------|
| **Latencia** | Alta | Baja |
| **Tipo de Datos** | Hist√≥ricos | En tiempo real |
| **Ventanas** | No aplica | `Fixed`, `Sliding`, `Session` |
| **Casos de Uso** | Reportes, ETLs | An√°lisis en tiempo real, IoT |

---

## **3Ô∏è‚É£ Patrones de Procesamiento de Datos en Dataflow**  
### **üîπ 1. Transformaciones Elementales**  
‚úî **Map (`ParDo`)** ‚Üí Aplica una transformaci√≥n a cada elemento.  
‚úî **Filter** ‚Üí Filtra elementos seg√∫n una condici√≥n.  
‚úî **FlatMap** ‚Üí Expande un elemento en m√∫ltiples elementos.  

```python
def convertir_a_mayusculas(elemento):
    return elemento.upper()

p | 'Convertir' >> beam.Map(convertir_a_mayusculas)
```

---

### **üîπ 2. Agrupaci√≥n de Datos**  
‚úî **GroupByKey** ‚Üí Agrupa elementos con la misma clave.  
‚úî **CombinePerKey** ‚Üí Aplica una funci√≥n de agregaci√≥n a cada grupo.  

```python
p | 'Agrupar por clave' >> beam.GroupByKey()
```

‚úî **Ejemplo: Contar ocurrencias de palabras**  
```python
(p
 | 'Leer Texto' >> beam.io.ReadFromText('gs://mi-bucket/datos.txt')
 | 'Separar Palabras' >> beam.FlatMap(lambda x: x.split())
 | 'Mapear Palabras' >> beam.Map(lambda x: (x, 1))
 | 'Contar' >> beam.CombinePerKey(sum)
 | 'Escribir' >> beam.io.WriteToText('gs://mi-bucket/salida'))
```

---

### **üîπ 3. Ventanas en Streaming**  
‚úî **Fixed Window** ‚Üí Intervalos fijos de tiempo (ej. cada 5 min).  
‚úî **Sliding Window** ‚Üí Se superponen en el tiempo (ej. cada 5 min con deslizamiento de 2 min).  
‚úî **Session Window** ‚Üí Basado en per√≠odos de inactividad.  

**Ejemplo de Ventana Fija**  
```python
import apache_beam.transforms.window as window

(p 
 | 'Leer de Pub/Sub' >> beam.io.ReadFromPubSub(topic='projects/mi-proyecto/topics/mi-topico')
 | 'Aplicar Ventana' >> beam.WindowInto(window.FixedWindows(60))  # Ventana de 60 segundos
 | 'Escribir en BigQuery' >> beam.io.WriteToBigQuery('mi-proyecto:mi_dataset.mi_tabla'))
```

---

### **üîπ 4. Patrones de Join en Dataflow**  
‚úî **CoGroupByKey** ‚Üí Une dos PCollections por clave com√∫n.  
‚úî **Side Inputs** ‚Üí Permite usar una PCollection secundaria como par√°metro en una transformaci√≥n.  

**Ejemplo de CoGroupByKey (Uni√≥n de Datos)**  
```python
p1 = p | 'Dataset 1' >> beam.Create([('A', 1), ('B', 2)])
p2 = p | 'Dataset 2' >> beam.Create([('A', 3), ('B', 4)])

(p1, p2) | 'Unir Datos' >> beam.CoGroupByKey()
```

---

### **üîπ 5. Manejo de Agua y Retrasos en Streaming**  
‚úî **Watermarks** ‚Üí Controla el tiempo m√°ximo de espera para eventos retrasados.  
‚úî **Allowed Lateness** ‚Üí Define cu√°nto tiempo aceptar eventos tard√≠os.  
‚úî **Late Data Handling** ‚Üí Env√≠a eventos tard√≠os a un destino separado.  

```python
(p 
 | 'Aplicar Ventana' >> beam.WindowInto(window.FixedWindows(60), allowed_lateness=120))
```

---

# **‚úÖ Resumen y Estrategia de Uso en Dataflow**
| **T√©cnica** | **Beneficio** | **Cu√°ndo Usarla** |
|------------|--------------|------------------|
| **Batch Processing** | Procesa datos hist√≥ricos | ETLs, Reportes |
| **Streaming Processing** | Responde a eventos en tiempo real | Logs, IoT, An√°lisis en Vivo |
| **Ventanas (Fixed, Sliding, Session)** | Procesa datos en per√≠odos de tiempo | Casos en tiempo real |
| **GroupByKey, CoGroupByKey** | Agrega datos y combina fuentes | Enriquecimiento de datos |
| **Allowed Lateness** | Maneja eventos tard√≠os | Datos de sensores o logs |
