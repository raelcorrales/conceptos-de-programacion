# **ğŸ“Œ GuÃ­a de Cloud Composer (Apache Airflow en GCP)**  

## **1ï¸âƒ£ IntroducciÃ³n a Cloud Composer y Apache Airflow**  

### **ğŸ”¹ Â¿QuÃ© es Cloud Composer?**  
Cloud Composer es un servicio **gestionado** de Apache Airflow en Google Cloud. Permite la **orquestaciÃ³n de flujos de trabajo** para mover, transformar y procesar datos en GCP y otros entornos.  

âœ” **AdministraciÃ³n gestionada**: Google Cloud gestiona Airflow, reduciendo la sobrecarga operativa.  
âœ” **IntegraciÃ³n con GCP**: Compatible con BigQuery, Dataflow, GCS, Pub/Sub, Dataproc, etc.  
âœ” **Escalabilidad**: Se ejecuta sobre Kubernetes en GKE.  
âœ” **ProgramaciÃ³n y monitoreo**: Permite definir flujos de trabajo en Python y monitorearlos desde una UI web.  

---

## **2ï¸âƒ£ Arquitectura de Apache Airflow en Cloud Composer**  
Cloud Composer usa **Apache Airflow**, que sigue la siguiente arquitectura:  

1. **DAGs (Directed Acyclic Graphs)** â†’ Flujos de trabajo en Python.  
2. **Scheduler** â†’ Programa la ejecuciÃ³n de tareas segÃºn la definiciÃ³n del DAG.  
3. **Executor** â†’ Ejecuta las tareas (Celery, Kubernetes o Local).  
4. **Metastore Database** â†’ Almacena metadatos sobre DAGs y ejecuciones.  
5. **Web Server (UI)** â†’ Interfaz para monitorear DAGs y tareas.  

---

## **3ï¸âƒ£ CreaciÃ³n de DAGs en Cloud Composer**  
### **ğŸ”¹ Â¿QuÃ© es un DAG?**  
Un **DAG (Directed Acyclic Graph)** es un conjunto de tareas organizadas en una estructura sin ciclos, donde cada nodo es una tarea y las aristas representan dependencias.  

**Ejemplo bÃ¡sico de un DAG en Apache Airflow:**  
```python
from airflow import DAG
from airflow.operators.dummy_operator import DummyOperator
from airflow.utils.dates import days_ago

# Definir el DAG
dag = DAG(
    dag_id="mi_primer_dag",
    schedule_interval="@daily",
    start_date=days_ago(1),
    catchup=False
)

# Definir tareas
tarea_1 = DummyOperator(task_id="inicio", dag=dag)
tarea_2 = DummyOperator(task_id="fin", dag=dag)

# Definir flujo de ejecuciÃ³n
tarea_1 >> tarea_2
```

âœ” **`dag_id`** â†’ Identificador del DAG.  
âœ” **`schedule_interval`** â†’ Frecuencia de ejecuciÃ³n (`@daily`, `@hourly`, `*/5 * * * *`).  
âœ” **`start_date`** â†’ Fecha de inicio del DAG.  
âœ” **`catchup=False`** â†’ Evita ejecuciÃ³n retroactiva de DAGs pasados.  
âœ” **`DummyOperator`** â†’ Representa una tarea sin acciÃ³n (Ãºtil para testing).  

---

## **4ï¸âƒ£ Dependencias entre Tareas en Airflow**  
Las dependencias entre tareas en Airflow se definen con `>>` (dependencia directa) y `<<` (dependencia inversa).  

### **ğŸ”¹ Dependencias Simples**  
```python
tarea_1 >> tarea_2  # tarea_2 depende de tarea_1
```

### **ğŸ”¹ Dependencias MÃºltiples**  
```python
tarea_1 >> [tarea_2, tarea_3]  # tarea_1 ejecuta tarea_2 y tarea_3 en paralelo
```

### **ğŸ”¹ Dependencias Encadenadas**  
```python
tarea_1 >> tarea_2 >> tarea_3  # EjecuciÃ³n secuencial
```

---

## **5ï¸âƒ£ Tipos de Operadores en Apache Airflow**  
Apache Airflow proporciona mÃºltiples operadores para definir tareas en un DAG:  

| **Operador** | **DescripciÃ³n** | **Ejemplo** |
|-------------|----------------|-------------|
| `DummyOperator` | Tarea vacÃ­a usada para estructurar DAGs | `DummyOperator(task_id='dummy')` |
| `PythonOperator` | Ejecuta funciones Python | `PythonOperator(task_id='funcion', python_callable=mi_funcion)` |
| `BashOperator` | Ejecuta comandos Bash | `BashOperator(task_id='bash', bash_command='echo "Hola"')` |
| `BigQueryOperator` | Ejecuta consultas en BigQuery | `BigQueryOperator(task_id='consulta', sql='SELECT * FROM tabla')` |
| `DataflowTemplateOperator` | Ejecuta un job de Dataflow | `DataflowTemplateOperator(task_id='dataflow_job', template='gs://ruta/template')` |

**Ejemplo de un DAG con PythonOperator:**  
```python
from airflow.operators.python_operator import PythonOperator

def mi_funcion():
    print("Â¡Ejecutando tarea en Python!")

tarea_python = PythonOperator(
    task_id="ejecutar_python",
    python_callable=mi_funcion,
    dag=dag
)

tarea_1 >> tarea_python >> tarea_2
```

---

## **6ï¸âƒ£ Agendamiento y Control de EjecuciÃ³n en Airflow**  
### **ğŸ”¹ Intervalos de EjecuciÃ³n (`schedule_interval`)**  
Airflow permite definir la frecuencia de ejecuciÃ³n de los DAGs con expresiones crontab o keywords:  

| **ExpresiÃ³n** | **Frecuencia** |
|--------------|--------------|
| `@once` | Una sola vez |
| `@hourly` | Cada hora |
| `@daily` | Diario |
| `*/5 * * * *` | Cada 5 minutos |

**Ejemplo de DAG con ejecuciÃ³n cada 5 minutos:**  
```python
dag = DAG(
    dag_id="dag_cada_5_min",
    schedule_interval="*/5 * * * *",
    start_date=days_ago(1),
    catchup=False
)
```

---

## **7ï¸âƒ£ EjecuciÃ³n Condicional y Retries en Airflow**  
### **ğŸ”¹ ConfiguraciÃ³n de Retries**  
Se pueden definir intentos de reintento (`retries`) y tiempos de espera entre ellos (`retry_delay`).  

```python
from datetime import timedelta

tarea = BashOperator(
    task_id="reintento",
    bash_command="exit 1",  # Simula un fallo
    retries=3,
    retry_delay=timedelta(minutes=5),
    dag=dag
)
```

âœ” **`retries=3`** â†’ Reintenta la tarea hasta 3 veces si falla.  
âœ” **`retry_delay=timedelta(minutes=5)`** â†’ Espera 5 minutos entre intentos.  

---

## **8ï¸âƒ£ XComs: ComunicaciÃ³n entre Tareas en Airflow**  
XComs permiten compartir datos entre tareas dentro de un DAG.  

### **ğŸ”¹ Enviar un Valor con `xcom_push`**  
```python
def enviar_valor(**kwargs):
    kwargs['ti'].xcom_push(key='mensaje', value='Hola desde XCom')

tarea_envio = PythonOperator(
    task_id="enviar",
    python_callable=enviar_valor,
    provide_context=True,
    dag=dag
)
```

### **ğŸ”¹ Recuperar un Valor con `xcom_pull`**  
```python
def recibir_valor(**kwargs):
    mensaje = kwargs['ti'].xcom_pull(task_ids='enviar', key='mensaje')
    print(f"Mensaje recibido: {mensaje}")

tarea_recibo = PythonOperator(
    task_id="recibir",
    python_callable=recibir_valor,
    provide_context=True,
    dag=dag
)
```

âœ” `xcom_push` â†’ EnvÃ­a datos.  
âœ” `xcom_pull` â†’ Recupera datos.  

---

# **âœ… Resumen y Estrategia para Usar Cloud Composer**
| **Funcionalidad** | **Uso** |
|------------------|--------|
| **DAGs** | Definir flujos de trabajo |
| **Operadores** | Ejecutar tareas en Python, Bash, SQL, GCP |
| **Dependencias** | Definir orden de ejecuciÃ³n |
| **Schedule Interval** | Programar ejecuciones con crontab |
| **XComs** | Compartir datos entre tareas |
| **Retries** | Manejar fallos y reintentos |
